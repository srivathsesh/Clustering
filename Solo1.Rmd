---
title: "Market Segmentation and Product recommendation"
author: "Sri Seshadri"
date: "10/13/2018"
output: 
pdf_document:
  toc: true
  toc_depth: 3
  fig_caption: yes
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F)
load("apphappyData.RData")
library(dplyr)
library(magrittr)
library(caret)
library(purrr)
```

## 1. Introduction

The App Happy company is currently in the business of providing B2B analytic apps. It is wanting to diversity its product portfolio and is exploring entering new market in the entertainment space. In order to make an informed decision on new market entry, the company surveyed the consumers using a third party surveyor (Consumer Spy Corp). This report discusses the analysis of the survey to explore the segments of customers in the market. The analysis also explores the products in the market based on the survey and touches on potential opportunities for product differentiation. The analysis also explores possible marketing strategy to reach the various segments of the market. However market sizing and market growth rate is out of scope of this analysis. The report discusses the analytical techniques used to segment the markets and use of typing tools to classify new customers on whom there is no existent data. The report also discusses further research to improve the accuracy of typing tools.

## 2. Executive Summary

## 3. Data

The survey conducted by Consumer Spy Corp was extensive, however not all question's responses was shared with us. We had access to responses to questions covering the topics of a) demography such as age, race, education, income, sex and marital status etc. b) Tpe of web-enabled devices and the type of apps the consumers use c) Attitude of customers towards new technology, products and personality. Responses to 16 questions were shared with us. The attitudinal questions solicited response in Likert scale. There were 5.5% and 1.33% missing responses for questions on percentage of your apps that were free and gender respectively. Missing data was imputed for analysis.

```{r}

SurveyData <- apphappy.3.num.frame
Summary <- skimr::skim(SurveyData)

```


## 4. Feature Engineering

The questions and responses surrounding the attitudes of customers were lumped together using the KJ method or affinity diagram, based on common themes. The engineered features and the formula are shown in the table below. The Survey is previded in the Appendix for reference. It is to be noted that the 6th statement in question 25 has a negative conotation compared to the other statements in the question. Hence the score of statement is given an negative weightage, as seen in the last row of table 1.

```{r}
TechAttitude <- paste0("q24r",c(1,2,4,5,6))
TechUseSocial <- paste0("q24r",c(9,10,11,12))
TechUseMusic <- paste0("q24r",c(7))
TechUseVideo <- paste0("q24r",c(8))

ShoppingAttitude <- c(paste0("q26r",c(3,4,5,6,18,7,13,14,15,16)),"q24r3")
AppPref <- paste0("q24r",c(8,9,10,11,12))

TechAttitudeFormula <- paste0('mean(',paste(TechAttitude,collapse = ","),')')
TechUseSocialFormula <- paste0('mean(',paste(TechUseSocial,collapse = ","),')')
TechUseMusicFormula <- paste0('mean(',paste(TechUseSocial,collapse = ","),')')
TechUseVideoFormula <- paste0('mean(',paste(TechUseVideo,collapse = ","),')')
ShoppingAttitudeFormula <- paste0('mean(',paste(ShoppingAttitude,collapse = ","),')')
AppPrefFormula <- paste0('mean(',paste(AppPref,collapse = ","),')')

LeaderFormula <- paste0('(',paste0('q25r',paste0(c(1,2,3,4,5,7,8,9,10,11,12)),collapse = "+"),'-q25r6)/12')

EngineeredFeature <- c('TechAttitudeMean','TechUseSocialMean','TechUseMusiclMean','TechUseVideoMean','ShoppingAttitudeMean','AppPrefMean','LeaderMean')
Formula <- c(TechAttitudeFormula,TechUseSocialFormula,TechUseMusicFormula,TechUseVideoFormula,ShoppingAttitudeFormula,AppPrefFormula,LeaderFormula)

knitr::kable(data.frame(Feature = EngineeredFeature, Formula = Formula), caption = "Feature engineering")

```


```{r,eval = F}
SurveyData %<>% select(-q5r1,-q2r10)
cormat <- cor(SurveyData,use = "complete.obs")
corrplot::corrplot(cormat,tl.cex = 0.6)
```


```{r}




SurveyData %>% 
  select(!!TechAttitude) %>% 
  rowMeans(.) -> TechAttitudeMean

SurveyData %>% 
  select(!!TechUseSocial) %>% 
  rowMeans(.) -> TechUseSocialMean

SurveyData %>% 
  select(!!TechUseMusic) %>% 
  rowMeans(.) -> TechUseMusiclMean

SurveyData %>% 
  select(!!TechUseVideo) %>% 
  rowMeans(.) -> TechUseVideoMean

SurveyData %>% 
  select(!!ShoppingAttitude) %>% 
  rowMeans(.) -> ShoppingAttitudeMean

SurveyData %>% 
  select(!!AppPref) %>% 
  rowMeans(.) -> AppPrefMean

SurveyData %>% 
  select(q13r1,q13r2,q13r3,q13r11) %>% 
  rowMeans(.) -> SocialWebMean

SurveyData %>% 
  select(q13r4,q13r7,q13r8,q13r9) %>% 
  rowMeans(.) -> RadioWebMean

SurveyData %>% 
  select(q13r5,q13r6,q13r10,q13r11) %>% 
  rowMeans(.) -> VideoWebMean

SurveyData %>% 
  select(starts_with('q24')) %>% 
  mutate(q24r6 = q24r6*-1) %>% 
  rowSums(.)/12-> LeaderMean


SurveyData <- cbind.data.frame(SurveyData
                               ,TechAttitudeMean
                               ,TechUseSocialMean
                               ,ShoppingAttitudeMean
                               ,AppPrefMean
                               ,SocialWebMean
                               ,RadioWebMean
                               ,VideoWebMean
                               ,LeaderMean)

# Remove redundant Questions 

SurveyData %<>%
  select(-starts_with('q24r')) %>% 
  select(-starts_with('q25r')) %>% 
  select(-starts_with('q26r')) %>% 
  select(-starts_with('q13r')) %>% 
  select(-starts_with('q50r')) %>% 
  select(-starts_with('q2r')) %>% 
  select(-starts_with('q12')) %>% 
  select(-starts_with('q49')) %>% 
  select(-q48,-q11,-q55,-q54,-q1,-q57)

# Data to show the cluster by exisitng market

SurveyData0 <- SurveyData %>%
  mutate(TVApp = q4r2 + q4r4,
         NewsApp = q4r7 + q4r9,
         Music = q4r1,
         Entertainment = q4r3,
         Gaming = q4r5,
         SocialNet = q4r6,
         ShoppingApp = q4r8,
         OtherApps = q4r10) %>% 
  select(-starts_with('q4r'))

# Data to show the attitudinal cluster

SurveyData %<>%
  mutate(TVApp = q4r2 + q4r4,
         NewsApp = q4r7 + q4r9,
         Music = q4r1,
         Entertainment = q4r3,
         Gaming = q4r5,
         SocialNet = q4r6,
         ShoppingApp = q4r8,
         OtherApps = q4r10,
         Income = q56) %>% 
  select(-starts_with('q4r'),-q56)

# Test out attitudinal cluster

SurveyData %<>% select(ends_with('Mean'),Income,caseID) 


# Remove CaseID and make it a rowname instead

 # `rownames<-`(SurveyData,SurveyData$caseID)
rownames(SurveyData) <- SurveyData$caseID
  SurveyData %<>% select(-caseID) 
  SurveyData0 %<>% select(-caseID)
  
```

# 5. Feature Selection & Assumptions

With ubiquitous use of technology in today's world, the use of web-enabled devices is in every age group, race and gender. The question now becomes 
- what are the consumers consuming on their devices? 
- Where is room for opportunities in terms of a new product? 
- What is/are the attitude(s) of the customers towards new content consumption? 




```{r}
cormat <- cor(SurveyData,use = "complete.obs")
corrplot::corrplot.mixed(cormat,tl.cex = 0.6,addCoefasPercent = T,number.cex=0.6)


```


```{r}
RedundantInfo <- colnames(cormat)[caret::findCorrelation(cormat)]
SurveyData %<>% 
  select(-AppPrefMean)

# Based on previous analysis
SurveyData0 %<>% 
  select(-AppPrefMean)
```

# Impute missing data

```{r,message=F}

imputedData <- mice::mice(SurveyData,printFlag = F)
SurveyData_copy <- mice::complete(imputedData)
rownames(SurveyData_copy) <- rownames(SurveyData)
SurveyData <- SurveyData_copy
rownames(SurveyData) <- rownames(SurveyData_copy)


imputedData0 <- mice::mice(SurveyData0,printFlag = F)
SurveyData_copy0 <- mice::complete(imputedData0)
rownames(SurveyData_copy0) <- rownames(SurveyData0)
SurveyData0 <- SurveyData_copy0
rownames(SurveyData0) <- rownames(SurveyData_copy0)


```

# Center and Standardize

```{r}
library(recipes)

rec <- recipe(SurveyData) %>% 
  step_center(everything()) %>% 
  step_scale(everything())

SurveyDataPrep <- prep(rec,training = SurveyData, retain = T)
#SurveyDataStd <- bake(SurveyDataPrep, newdata = SurveyData)
SurveyDataStd <- juice(SurveyDataPrep)

rec0 <- recipe(SurveyData0) %>% 
  step_center(everything()) %>% 
  step_scale(everything())


SurveyDataPrep0 <- prep(rec0,training = SurveyData0, retain = T)
#SurveyDataStd <- bake(SurveyDataPrep, newdata = SurveyData)
SurveyDataStd0 <- juice(SurveyDataPrep0)

```

# Get bootstrap samples

```{r}
set.seed(10)
bt_sampples <- rsample::bootstraps(SurveyDataStd, times = 25)

```

# Hierarchical cluster

```{r}
library(rsample)

# used first few samples' dendrogram to decide on the cut height to be 10
hierCluster <- function(sampleSplit){
  hc <- hclust(dist(analysis(sampleSplit)))
  cutree(hc,h=10)
}

bt_sampples %<>%
  mutate(HC = map(splits,hierCluster))

hist(map_dbl(bt_sampples$HC,max),
     main = 'Clusters in the 25 bootstrap samples',col = 'red',
     xlab = 'Number of Clusters')

```

# Applying 4 cluster solution to the hierarchical clusters

```{r}
library(cluster)
hc <- hclust(dist(SurveyDataStd))
hClusters <- cutree(hc,k = 3)


hc0 <- hclust(dist(SurveyDataStd0))
hClusters0 <- cutree(hc0,k = 4)

plot(cluster::silhouette(hClusters,daisy(SurveyDataStd)))

plot(cluster::silhouette(hClusters0,daisy(SurveyDataStd0)))
```

# R-Square stats for Hieracrchical


# K-mean Clustering

```{r}
library(cluster)
library(factoextra)
fviz_nbclust(SurveyDataStd,kmeans, method = "wss")

kmClusters <- kmeans(SurveyDataStd,3)

fviz_cluster(kmClusters,SurveyDataStd,  geom = "point", 
             ellipse= F, show.clust.cent = F,
             palette = "jco", ggtheme = theme_classic())


fviz_nbclust(SurveyDataStd0,kmeans, method = "wss")

kmClusters0 <- kmeans(SurveyDataStd0,3)

fviz_cluster(kmClusters0,SurveyDataStd0,  geom = "point", 
             ellipse= F, show.clust.cent = F,
             palette = "jco", ggtheme = theme_classic())
```

# pam

```{r}
fviz_nbclust(SurveyDataStd, pam, method = "wss")
pamclust <- pam(SurveyDataStd,3)
fviz_cluster(pamclust, 
             palette = "jco", # color palette
             ellipse = F,
             #ellipse.type = "t", # Concentration ellipse
             repel = F, # Avoid label overplotting (slow)
             labelsize = 3,
             ggtheme = theme_classic()
             )


fviz_nbclust(SurveyDataStd0, pam, method = "wss")
pamclust0 <- pam(SurveyDataStd,5)
fviz_cluster(pamclust0, 
             palette = "jco", # color palette
             ellipse = F,
             #ellipse.type = "t", # Concentration ellipse
             repel = F, # Avoid label overplotting (slow)
             labelsize = 3,
             ggtheme = theme_classic()
             )
```

# dbscan

```{r}
dbscan::kNNdistplot(SurveyDataStd, k =  6)
abline(h = 2.0, lty = 2)

dbscan::kNNdistplot(SurveyDataStd0, k =  6)
abline(h = 4.0, lty = 2)
```

```{r}
set.seed(123)
db <- fpc::dbscan(SurveyDataStd, eps = 2.0, MinPts = 5)
# Plot DBSCAN results
library("factoextra")
fviz_cluster(db, data = SurveyDataStd, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point",palette = "jco", ggtheme = theme_classic())


db0 <- fpc::dbscan(SurveyDataStd0, eps = 4.0, MinPts = 5)
# Plot DBSCAN results
library("factoextra")
fviz_cluster(db0, data = SurveyDataStd, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point",palette = "jco", ggtheme = theme_classic())
```

# tsne

```{r}
library(Rtsne)
rownames(SurveyDataStd) <- rownames(SurveyData)
tsne <- Rtsne::Rtsne(distinct(SurveyDataStd),dims = 2, perplexity=30, verbose=TRUE, max_iter = 500,pca_center = F)

dbscan::kNNdistplot(tsne$Y, k =  6)
abline(h = 1.5, lty = 2)


tsne0 <- Rtsne::Rtsne(SurveyDataStd0,dims = 2, perplexity=30, verbose=TRUE, max_iter = 500,pca_center = F)

dbscan::kNNdistplot(tsne0$Y, k =  6)
abline(h = 1.5, lty = 2)
```

```{r}
db2 <- fpc::dbscan(tsne$Y, eps = 1.5, MinPts = 3)

# Plot DBSCAN results
library("factoextra")
tsnedf <- tsne$Y
colnames(tsnedf) <- c('Dim1','Dim2')
fviz_cluster(db2, data = tsnedf, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point", ggtheme = theme_classic(),
             palette = 'fco')


db20 <- fpc::dbscan(tsne0$Y, eps = 1.5, MinPts = 3)

# Plot DBSCAN results
library("factoextra")
tsnedf0 <- tsne0$Y
colnames(tsnedf0) <- c('Dim1','Dim2')
fviz_cluster(db20, data = tsnedf0, stand = FALSE,
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point", ggtheme = theme_classic(),
             palette = 'fco')
```

```{r}
fviz_nbclust(tsnedf, pam, method = "wss")

fviz_nbclust(tsnedf0, pam, method = "wss")
```

```{r}
set.seed(10)
pamclust3 <- pam(tsnedf,3)
fviz_cluster(pamclust3, 
             palette = "jco", # color palette
             ellipse = T,
             #ellipse.type = "t", # Concentration ellipse
             repel = F, # Avoid label overplotting (slow)
             labelsize = 3,
             ggtheme = theme_classic(),
             stand = F
             )

pamclust4 <- pam(tsnedf,4)
fviz_cluster(pamclust4,
             palette = "jco", # color palette
             ellipse = T,
             #ellipse.type = "t", # Concentration ellipse
             repel = F, # Avoid label overplotting (slow)
             labelsize = 3,
             ggtheme = theme_classic(),
             stand = F
             )
# 
# pamclust5 <- pam(tsnedf,5)
# fviz_cluster(pamclust5, 
#              palette = "jco", # color palette
#              ellipse = T,
#              #ellipse.type = "t", # Concentration ellipse
#              repel = F, # Avoid label overplotting (slow)
#              labelsize = 3,
#              ggtheme = theme_classic(),
#              stand = F
#              )
# 
# pamclust6 <- pam(tsnedf,6)
# fviz_cluster(pamclust6, 
#              palette = "jco", # color palette
#              ellipse = T,
#              #ellipse.type = "t", # Concentration ellipse
#              repel = F, # Avoid label overplotting (slow)
#              labelsize = 3,
#              ggtheme = theme_classic(),
#              stand = F
#              )
# 
# pamclust7 <- pam(tsnedf,7)
# fviz_cluster(pamclust7, 
#              palette = "jco", # color palette
#              ellipse = T,
#              #ellipse.type = "t", # Concentration ellipse
#              repel = F, # Avoid label overplotting (slow)
#              labelsize = 3,
#              ggtheme = theme_classic(),
#              stand = F
#              )
# 
# pamclust8 <- pam(tsnedf,8)
# fviz_cluster(pamclust8, 
#              palette = "jco", # color palette
#              ellipse = T,
#              #ellipse.type = "t", # Concentration ellipse
#              repel = F, # Avoid label overplotting (slow)
#              labelsize = 3,
#              ggtheme = theme_classic(),
#              stand = F
#              )
set.seed(10)
pamclust09 <- pam(tsnedf0,9)
fviz_cluster(pamclust09, 
             palette = "jco", # color palette
             ellipse = T,
             #ellipse.type = "t", # Concentration ellipse
             repel = F, # Avoid label overplotting (slow)
             labelsize = 3,
             ggtheme = theme_classic(),
             stand = F
             )
```

```{r}
clusters <- pamclust3$clustering

# put it back into SurveyData
SurveyData %<>%
  mutate(rowname = row.names(.)) %>% 
  filter(!rowname %in% c("1083","1870","2223","655","998")) %>% 
  mutate(Clusters = clusters)
rownames(SurveyData) <- SurveyData$rowname
SurveyData %<>% select(-rowname) 
#rownames(SurveyData) <- rownames(SurveyData_copy)
# write to file

#write.csv(SurveyData,file = 'SurveyClusters.csv')



clusters0 <- pamclust09$clustering

# put it back into SurveyData
SurveyData0 %<>%
  mutate(Clusters = clusters0)
rownames(SurveyData0) <- rownames(SurveyData_copy0)
```

# Random Forest

```{r}
# Change Clusters into a factor
SurveyData$Clusters <- as.factor(SurveyData$Clusters)

# Train a classification tree
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
dtree_fit <- train(Clusters ~., data = SurveyData, method = "rpart",
                   trControl = trctrl,
                   tuneLength = 10)

mdlfit <- dtree_fit$finalModel

mdlfit <- partykit::as.party(mdlfit)

plot(mdlfit)



# Change Clusters into a factor
SurveyData0$Clusters <- as.factor(SurveyData0$Clusters)

# Train a classification tree
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
dtree_fit0 <- train(Clusters ~., data = SurveyData0, method = "rpart",
                   trControl = trctrl,
                   tuneLength = 10)

mdlfit0 <- dtree_fit0$finalModel

mdlfit0 <- partykit::as.party(mdlfit0)

plot(mdlfit0)
```

